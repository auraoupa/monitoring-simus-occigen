/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.5.215:35182'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.5.215:45757'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.5.215:45957'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.5.215:44600'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.5.215:40860'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.5.215:33783'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.5.215:36240'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.5.215:38846'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.5.215:41641'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.5.215:32970'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.5.215:32918'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.5.215:41135'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.5.215:35188'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.5.215:40973'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.5.215:43920'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.5.215:33921'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.5.215:37135'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.5.215:38585'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.5.215:42685'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.5.215:34394'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.5.215:41010'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.5.215:41173'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.5.215:46318'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.5.215:44702'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.5.215:39143'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.5.215:41199'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.5.215:42344'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.5.215:44168'
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-haks1yiw', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-v17uf4g_', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-hig3jpqg', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-0bnbr51h', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-v_tcpgri', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-vgcxeu5j', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-smc6ct4z', purging
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.5.215:41999
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.5.215:35563
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.5.215:42803
distributed.worker - INFO -          Listening to:   tcp://172.30.5.215:41999
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.5.215:42059
distributed.worker - INFO -          Listening to:   tcp://172.30.5.215:35563
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.5.215:44971
distributed.worker - INFO -              nanny at:         172.30.5.215:44600
distributed.worker - INFO -          Listening to:   tcp://172.30.5.215:42803
distributed.worker - INFO -              nanny at:         172.30.5.215:35182
distributed.worker - INFO -          Listening to:   tcp://172.30.5.215:42059
distributed.worker - INFO -              bokeh at:         172.30.5.215:45996
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.5.215:38090
distributed.worker - INFO -          Listening to:   tcp://172.30.5.215:44971
distributed.worker - INFO -              nanny at:         172.30.5.215:44702
distributed.worker - INFO -              bokeh at:         172.30.5.215:37039
distributed.worker - INFO -              nanny at:         172.30.5.215:43920
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.5.215:38062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO -              nanny at:         172.30.5.215:41173
distributed.worker - INFO -              bokeh at:         172.30.5.215:42300
distributed.worker - INFO -          Listening to:   tcp://172.30.5.215:38090
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO -              bokeh at:         172.30.5.215:44393
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -              bokeh at:         172.30.5.215:40110
distributed.worker - INFO -          Listening to:   tcp://172.30.5.215:38062
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.5.215:39180
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO -              nanny at:         172.30.5.215:33921
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.5.215:35239
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO -              nanny at:         172.30.5.215:33783
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.5.215:36417
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.5.215:36183
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -              bokeh at:         172.30.5.215:45901
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:   tcp://172.30.5.215:39180
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.5.215:45366
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.5.215:46674
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -              bokeh at:         172.30.5.215:34706
distributed.worker - INFO -          Listening to:   tcp://172.30.5.215:35239
distributed.worker - INFO -          Listening to:   tcp://172.30.5.215:36417
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -          Listening to:   tcp://172.30.5.215:36183
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -              nanny at:         172.30.5.215:46318
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO -          Listening to:   tcp://172.30.5.215:45366
distributed.worker - INFO -          Listening to:   tcp://172.30.5.215:46674
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -              bokeh at:         172.30.5.215:43383
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-4eg25oi3
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-icyy6p6v', purging
distributed.worker - INFO -              nanny at:         172.30.5.215:40973
distributed.worker - INFO -              nanny at:         172.30.5.215:42344
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-wpsercgt
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -              nanny at:         172.30.5.215:41135
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -              nanny at:         172.30.5.215:40860
distributed.worker - INFO -              nanny at:         172.30.5.215:32970
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-a4ouhk4n
distributed.worker - INFO -              bokeh at:         172.30.5.215:33502
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-0ye5sbt6
distributed.worker - INFO -              bokeh at:         172.30.5.215:46394
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-om5a2t21
distributed.worker - INFO -              bokeh at:         172.30.5.215:38314
distributed.worker - INFO -              bokeh at:         172.30.5.215:35513
distributed.worker - INFO -              bokeh at:         172.30.5.215:33084
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ho4l684u
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-56c02u9a
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-5zvif78n
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-9d139_cx
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-w92no_3l
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-63n3ha8v
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-iixl355s
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-h4n213fl
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.5.215:38775
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.5.215:37685
distributed.worker - INFO -          Listening to:   tcp://172.30.5.215:37685
distributed.worker - INFO -          Listening to:   tcp://172.30.5.215:38775
distributed.worker - INFO -              nanny at:         172.30.5.215:35188
distributed.worker - INFO -              nanny at:         172.30.5.215:41199
distributed.worker - INFO -              bokeh at:         172.30.5.215:38315
distributed.worker - INFO -              bokeh at:         172.30.5.215:39238
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-v_1pz1rp
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-e7tq9yd1
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.5.215:38268
distributed.worker - INFO -          Listening to:   tcp://172.30.5.215:38268
distributed.worker - INFO -              nanny at:         172.30.5.215:38846
distributed.worker - INFO -              bokeh at:         172.30.5.215:39755
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-pjh_594m
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.5.215:37661
distributed.worker - INFO -          Listening to:   tcp://172.30.5.215:37661
distributed.worker - INFO -              nanny at:         172.30.5.215:37135
distributed.worker - INFO -              bokeh at:         172.30.5.215:35708
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-xmg8oi5i
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:44062
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:44062
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:44062
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:44062
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.5.215:37898
distributed.worker - INFO -          Listening to:   tcp://172.30.5.215:37898
distributed.worker - INFO -              nanny at:         172.30.5.215:36240
distributed.worker - INFO -              bokeh at:         172.30.5.215:43013
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-_f5nnx6l
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:44062
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-g14osbzt', purging
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:44062
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.5.215:36841
distributed.worker - INFO -          Listening to:   tcp://172.30.5.215:36841
distributed.worker - INFO -              nanny at:         172.30.5.215:34394
distributed.worker - INFO -              bokeh at:         172.30.5.215:34532
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-jjkhl598
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:44062
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-0jizzc7o', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-3mxsc55v', purging
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.5.215:38975
distributed.worker - INFO -          Listening to:   tcp://172.30.5.215:38975
distributed.worker - INFO -              nanny at:         172.30.5.215:45757
distributed.worker - INFO -              bokeh at:         172.30.5.215:38322
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-zabbd423
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.5.215:39812
distributed.worker - INFO -          Listening to:   tcp://172.30.5.215:39812
distributed.worker - INFO -              nanny at:         172.30.5.215:38585
distributed.worker - INFO -              bokeh at:         172.30.5.215:42992
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-kte5u51p
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.5.215:43408
distributed.worker - INFO -          Listening to:   tcp://172.30.5.215:43408
distributed.worker - INFO -              nanny at:         172.30.5.215:41641
distributed.worker - INFO -              bokeh at:         172.30.5.215:37072
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-kofb8t6r
distributed.worker - INFO - -------------------------------------------------
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-wvk948jn', purging
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.5.215:39405
distributed.worker - INFO -          Listening to:   tcp://172.30.5.215:39405
distributed.worker - INFO -              nanny at:         172.30.5.215:44168
distributed.worker - INFO -              bokeh at:         172.30.5.215:35501
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:44062
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-5xya9viz
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:44062
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.5.215:44237
distributed.worker - INFO -          Listening to:   tcp://172.30.5.215:44237
distributed.worker - INFO -              nanny at:         172.30.5.215:32918
distributed.worker - INFO -              bokeh at:         172.30.5.215:41053
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-8p3v7fgo
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:44062
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.5.215:46562
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:   tcp://172.30.5.215:46562
distributed.worker - INFO -              nanny at:         172.30.5.215:41010
distributed.core - INFO - Starting established connection
distributed.worker - INFO -              bokeh at:         172.30.5.215:41686
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-2r1hdw3z
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.5.215:41311
distributed.worker - INFO -          Listening to:   tcp://172.30.5.215:41311
distributed.worker - INFO -              nanny at:         172.30.5.215:42685
distributed.worker - INFO -              bokeh at:         172.30.5.215:45820
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:   tcp://172.30.5.215:45273
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          Listening to:   tcp://172.30.5.215:45273
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -              nanny at:         172.30.5.215:39143
distributed.worker - INFO -              bokeh at:         172.30.5.215:45543
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-dsi4d1at
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-rbgzi6ge
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:44062
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ovlac7tm', purging
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:44062
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:44062
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:44062
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:44062
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-3tmyn2vz', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-dtn_9f0f', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-997vo0sr', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-wvf1_v4w', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ae_ojiiq', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-xb3zp8g_', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-h6j2nd_0', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-r7x2w5k4', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-3tvb9ypj', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-nxnwvbpw', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-twrthgxj', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ob7067q2', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-xt7saazw', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-e7uk13d7', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-45g2xjj1', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-2sse8dnh', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-soptz9sg', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-mqmm9rwe', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-igpugij4', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-353vto8u', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-3l5bbn3_', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-_4kmjif1', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-v2hgcbbt', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-xgnj3avq', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-tq8ptbc5', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-37nflkbd', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-1z1xilpj', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-cqqzjnn0', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-on4gjmih', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-6vr6rwb5', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-oag6h_t1', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-e0vwqa9w', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-yfyigese', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-p4xuzkyc', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-w5dwpe90', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-da9yemse', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-0csrz8f9', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-8yt_busx', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-1kg458wc', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-_v4385xa', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-210njgkh', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ei_x8un1', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-hnzi2gd2', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-jfgxq15l', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-x38vfv2u', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-m7tn2t7h', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-l96o9ahh', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-gix6eypn', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-mkcjmj4_', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-by3uneqo', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ayynpoyt', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-u8y2xfmc', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-vor4s0gk', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-mja4hx_e', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-shwgtas6', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-cvptce_s', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-38fu_s3u', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-i9hf9yl7', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-r35cxrhf', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-1qccv7bf', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-qdd8cyp1', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-alkblzyk', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-8j7yposh', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ljao3wc9', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-bdwmtnkk', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-gtl83231', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-wa9q289w', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-8zf7wuii', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-azvachyw', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ldmfbq9z', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-889sbae3', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-_xr7ckzb', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-f9mav4jy', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-zy98a0on', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-i_oqc2bk', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-8g105bsb', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-jfngreok', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-4ql98ago', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-y4x96mj4', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-vd1yjjem', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-o24uczko', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-nselpa_u', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-kt1fuy8r', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-uehikg59', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-kf8lxdk3', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-6dp38hk1', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-s26nbfq0', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-r6ztn5u9', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ar7dwlsz', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-bnmgnvg8', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-4eyz3nw5', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-e10515ol', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-of2m_6po', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-x4xa3c7c', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-xjt_1zom', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-navr7i0n', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-y6lwhit5', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-wekqfz1a', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-cevvt4s_', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-t07tnvto', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ylw83785', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-6smdbvim', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-snyxp331', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ax4ytv_o', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-7w_3oehl', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-1cve_xs9', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-uunmpbnw', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-8wv1hu3i', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ujerekhu', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-datxslrs', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-icani7tq', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-j950uuyv', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-t1cc8wlh', purging
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:44062
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:44062
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:44062
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:44062
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:44062
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:44062
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:44062
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:44062
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:44062
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:44062
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:44062
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:44062
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-wh54lj3g', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-9b24mze8', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-s34q8toy', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-unh67nt3', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-wjvtrkcq', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-xczayqqp', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-62jcehli', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-xpjbxodk', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-py310thm', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-jtfandaj', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-1q8coie_', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-m2rmxjx0', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-mgqfzwgj', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-nzm3v1gt', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-y4uum3df', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-qwfumm6e', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-kt21bcjs', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-qf9kl7co', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-wu3de4ts', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-gpjpa7jr', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-z1dfhjrz', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-_ri1ciax', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-woyywjf5', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-o9c8dmnw', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-sgb27br8', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-xrmy5cq6', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-chr1qznp', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-c6k7fi4n', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-6ksx8bby', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-stkb6yhr', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-27vuoph_', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-gz_r0ik0', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-1yowab9q', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-be3igtzx', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-hbhmjj8p', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-guwce174', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-9wfa4yyo', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-gipun5f5', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-m4tun_u9', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-m0722zgp', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ej0mmz8h', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-b4e3ej2x', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ez1go8hf', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-4glq74qj', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-4m9tf9ez', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-j9lg6u6v', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-_p1i_13g', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-jlfyhqp9', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-q5xyy7g4', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-n5186w9j', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-oc23x8tj', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-p1251uyt', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-l0oh0j9s', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ekppof21', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ew1kfm7_', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-njw_q39e', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-dbab_1lc', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-vlobx7ta', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-s5v3awhn', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-bh51_gz0', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-5qhy377o', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-excopwqa', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-js3osn8d', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-tbe7v756', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-7pgivn3u', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-6w3l7wpj', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-8y_wxijf', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-k9_c2og9', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-36rk5xrs', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-nkkh1qdp', purging
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:   tcp://172.30.5.215:46270
distributed.worker - INFO -          Listening to:   tcp://172.30.5.215:46270
distributed.worker - INFO -              nanny at:         172.30.5.215:45957
distributed.worker - INFO -              bokeh at:         172.30.5.215:43875
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-y75szlog
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.1:44062
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.utils_perf - INFO - full garbage collection released 16.57 MB from 1695 reference cycles (threshold: 10.00 MB)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.utils_perf - INFO - full garbage collection released 25.91 MB from 1275 reference cycles (threshold: 10.00 MB)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.utils_perf - INFO - full garbage collection released 63.07 MB from 1536 reference cycles (threshold: 10.00 MB)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.utils_perf - INFO - full garbage collection released 194.15 MB from 1539 reference cycles (threshold: 10.00 MB)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.utils_perf - INFO - full garbage collection released 60.33 MB from 2316 reference cycles (threshold: 10.00 MB)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.utils_perf - INFO - full garbage collection released 501.90 MB from 2242 reference cycles (threshold: 10.00 MB)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.utils_perf - INFO - full garbage collection released 100.80 MB from 2716 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 173.89 MB from 2187 reference cycles (threshold: 10.00 MB)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.worker - ERROR - Worker stream died during communication: tcp://172.30.8.134:40766
Traceback (most recent call last):
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/comm/core.py", line 218, in connect
    quiet_exceptions=EnvironmentError,
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
tornado.util.TimeoutError: Timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/worker.py", line 1827, in gather_dep
    self.rpc, deps, worker, who=self.address
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 742, in run
    yielded = self.gen.throw(*exc_info)  # type: ignore
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/worker.py", line 2965, in get_data_from_worker
    comm = yield rpc.connect(worker)
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 742, in run
    yielded = self.gen.throw(*exc_info)  # type: ignore
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/core.py", line 864, in connect
    connection_args=self.connection_args,
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 742, in run
    yielded = self.gen.throw(*exc_info)  # type: ignore
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/comm/core.py", line 230, in connect
    _raise(error)
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/comm/core.py", line 207, in _raise
    raise IOError(msg)
OSError: Timed out trying to connect to 'tcp://172.30.8.134:40766' after 10 s: in <distributed.comm.tcp.TCPConnector object at 0x2ab132b95898>: ConnectionRefusedError: [Errno 111] Connection refused
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.worker - ERROR - Worker stream died during communication: tcp://172.30.8.134:40766
Traceback (most recent call last):
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/comm/core.py", line 218, in connect
    quiet_exceptions=EnvironmentError,
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
tornado.util.TimeoutError: Timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/worker.py", line 1827, in gather_dep
    self.rpc, deps, worker, who=self.address
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 742, in run
    yielded = self.gen.throw(*exc_info)  # type: ignore
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/worker.py", line 2965, in get_data_from_worker
    comm = yield rpc.connect(worker)
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 742, in run
    yielded = self.gen.throw(*exc_info)  # type: ignore
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/core.py", line 864, in connect
    connection_args=self.connection_args,
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 735, in run
    value = future.result()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/gen.py", line 742, in run
    yielded = self.gen.throw(*exc_info)  # type: ignore
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/comm/core.py", line 230, in connect
    _raise(error)
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/comm/core.py", line 207, in _raise
    raise IOError(msg)
OSError: Timed out trying to connect to 'tcp://172.30.8.134:40766' after 10 s: in <distributed.comm.tcp.TCPConnector object at 0x2ab132fd78d0>: ConnectionRefusedError: [Errno 111] Connection refused
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.utils_perf - INFO - full garbage collection released 253.68 MB from 2322 reference cycles (threshold: 10.00 MB)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.utils_perf - INFO - full garbage collection released 41.47 MB from 3629 reference cycles (threshold: 10.00 MB)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.utils_perf - INFO - full garbage collection released 70.69 MB from 3019 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 35.89 MB from 4821 reference cycles (threshold: 10.00 MB)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.utils_perf - INFO - full garbage collection released 31.18 MB from 1559 reference cycles (threshold: 10.00 MB)
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version
  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:28: RuntimeWarning: invalid value encountered in true_divide
  x = np.divide(x1, x2, out)
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.utils_perf - INFO - full garbage collection released 11.20 MB from 4360 reference cycles (threshold: 10.00 MB)
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.1:44062
distributed.worker - INFO - Stopping worker at tcp://172.30.5.215:44971
distributed.worker - INFO - Stopping worker at tcp://172.30.5.215:42803
distributed.worker - INFO - Stopping worker at tcp://172.30.5.215:36183
distributed.worker - INFO - Stopping worker at tcp://172.30.5.215:38062
distributed.worker - INFO - Stopping worker at tcp://172.30.5.215:45366
distributed.worker - INFO - Stopping worker at tcp://172.30.5.215:46270
distributed.worker - INFO - Stopping worker at tcp://172.30.5.215:41311
distributed.worker - INFO - Stopping worker at tcp://172.30.5.215:38775
distributed.worker - INFO - Stopping worker at tcp://172.30.5.215:46674
distributed.worker - INFO - Stopping worker at tcp://172.30.5.215:37661
distributed.worker - INFO - Stopping worker at tcp://172.30.5.215:36841
distributed.worker - INFO - Stopping worker at tcp://172.30.5.215:45273
distributed.worker - INFO - Stopping worker at tcp://172.30.5.215:38975
distributed.worker - INFO - Stopping worker at tcp://172.30.5.215:35563
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.5.215:41173'
distributed.worker - INFO - Stopping worker at tcp://172.30.5.215:35239
distributed.worker - INFO - Stopping worker at tcp://172.30.5.215:39812
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.5.215:44702'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.5.215:41135'
distributed.worker - INFO - Stopping worker at tcp://172.30.5.215:38268
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.5.215:40860'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.5.215:42685'
distributed.worker - INFO - Stopping worker at tcp://172.30.5.215:39405
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.5.215:45957'
distributed.worker - INFO - Stopping worker at tcp://172.30.5.215:39180
distributed.worker - INFO - Stopping worker at tcp://172.30.5.215:37685
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.5.215:33783'
distributed.worker - INFO - Stopping worker at tcp://172.30.5.215:42059
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.5.215:37135'
distributed.worker - INFO - Stopping worker at tcp://172.30.5.215:41999
distributed.worker - INFO - Stopping worker at tcp://172.30.5.215:43408
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.5.215:35188'
distributed.worker - INFO - Stopping worker at tcp://172.30.5.215:38090
distributed.worker - INFO - Stopping worker at tcp://172.30.5.215:46562
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.5.215:32970'
distributed.worker - INFO - Stopping worker at tcp://172.30.5.215:36417
distributed.worker - INFO - Stopping worker at tcp://172.30.5.215:44237
distributed.worker - INFO - Stopping worker at tcp://172.30.5.215:37898
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.5.215:45757'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.5.215:35182'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.5.215:42344'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.5.215:38585'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.5.215:38846'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.5.215:46318'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.5.215:44168'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.5.215:43920'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.5.215:44600'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.5.215:41010'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.5.215:41199'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.5.215:41641'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.5.215:33921'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.5.215:32918'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.5.215:40973'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.5.215:36240'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.5.215:39143'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.5.215:34394'
distributed.dask_worker - INFO - End worker
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
